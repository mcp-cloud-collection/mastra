# AI Tracing Integration Test Suite

## **Overview**

A comprehensive integration test suite for Mastra's AI tracing functionality, featuring parameterized testing patterns and intelligent mock systems. The suite validates tracing across agents, workflows, tools, and their complex interactions.

**File**: `packages/core/src/ai-tracing/integration-tests.test.ts`

## **Current Status** 🎯

### **✅ Excellent Health: 18 Passing / 9 Skipped (66% Active Success)**

- **18 passing tests** ✅ - Core functionality working perfectly
- **9 skipped tests** ⏭️ - Implementation gaps identified and preserved for future work
- **0 failing tests** 🎯 - Clean, focused test suite
- **Fast execution**: <500ms total runtime

---

## **Test Architecture**

### **🔄 Parameterized Testing Pattern**

The suite uses data-driven testing to validate all agent generation methods comprehensively:

- `generateLegacy`
- `generateVNext`
- `streamLegacy`
- `streamVNext`

### **🧠 Intelligent Mock System**

**Smart Tool Detection**: Mock models intelligently call tools based on prompt content:

**Multi-Generation Support**: Handles up to 10 tool calls per type across parameterized tests.

### **📊 Advanced Logging & Debugging**

**Test-Specific Log Capture**:

- Logs are captured per test but only shown on failures
- Clean test runs with no spam
- Comprehensive failure debugging

**Usage**:

- Normal runs: `pnpm test` (clean, no spam)
- Debug mode: `AI_TRACING_VERBOSE=true pnpm test` (real-time logs)

---

## **Active Test Coverage** 📋

### **✅ Core Workflow Integration (4 tests)**

1. **Workflow with branching conditions** ✅
   - Multi-step workflow with conditional logic
   - Validates `WORKFLOW_RUN`, `WORKFLOW_STEP`, `WORKFLOW_CONDITIONAL` spans

2. **Unregistered workflow used as step** ✅
   - Tests workflow composition patterns
   - Validates nested workflow execution

3. **Tool used directly as workflow step** ✅
   - Direct tool execution within workflows
   - Validates tool integration patterns

4. **Metadata/child spans in workflow steps** ✅
   - Custom metadata injection via `tracingContext`
   - Child span creation and hierarchy

### **✅ Parameterized Agent Testing**

Each test below ran with:

- `generateLegacy`
- `generateVNext`
- `streamLegacy`
- `streamVNext`

**Agent with multiple tools**:

- Tests all 4 generation methods with intelligent tool calling
- Validates `AGENT_RUN`, `LLM_GENERATION`, `TOOL_CALL` spans
- Realistic multi-turn conversations with up to 10 tool calls

**TracingContext in tool calls**:

- **Custom metadata (4 tests)**: All methods × metadata injection
- **Child spans (4 tests)**: All methods × child span creation

**workflow launched inside agent tool**

- tracing context correctly propegates to workflow

### **✅ Specialized Features (2 tests)**

1. **Structured output (object generation)** ✅
   - Zod schema validation
   - Object generation pipeline testing

2. **Advanced TracingContext patterns** ✅
   - Custom metadata injection
   - Child span creation and management

---

## **Skipped Tests** ⏭️

### **Implementation Gaps Identified (9 tests skipped)**

These tests reveal specific areas needing AI tracing implementation work:

#### **Context Propagation Issues**

- agent launched inside workflow step
- workflow launched inside agent directly

#### **Workflow Nesting Issues**

- registered workflow nested in step in workflow

---

## **Development Workflow**

### **Adding New Tests**

1. **Single scenario tests**: Add directly to test suite
2. **Agent-based tests**: Consider adding to parameterized patterns
3. **Tool integration**: Use existing tool examples as templates

### **Debugging Failed Tests**

1. **Use verbose mode**: `AI_TRACING_VERBOSE=true pnpm test`
2. **Check failure logs**: Automatic log dumping on test failures
3. **Examine span sequences**: Logs show exact span creation order

### **Enabling Skipped Tests**

When implementation gaps are fixed:

1. Change `describe.skip.each` to `describe.each`
2. Change `it.skip` to `it`
3. Run tests to validate fixes
